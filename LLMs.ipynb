{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df09076",
   "metadata": {},
   "source": [
    "# LLMs API model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee52aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW RESPONSE ===\n",
      "{'id': 'ac609ce0536408072cce3d88d600e945', 'object': 'chat.completion', 'created': 1762513888, 'model': 'deepseek/deepseek-v3.2-exp', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '{\\n  \"summary\": [\\n    \"LLM là các mô hình học sâu lớn được đào tạo trước trên lượng dữ liệu khổng lồ\",\\n    \"Kiến trúc bộ chuyển hóa gồm mã hóa và giải mã với cơ chế tự tập trung, giúp hiểu mối quan hệ giữa từ và cụm từ\",\\n    \"Bộ chuyển hóa thực hiện đào tạo không giám sát, tự học ngữ pháp, ngôn ngữ và kiến thức cơ bản\",\\n    \"Khác với RNN xử lý tuần tự, bộ chuyển hóa xử lý song song toàn bộ trình tự, giảm đáng kể thời gian đào tạo\",\\n    \"Kiến trúc cho phép mô hình cực lớn với hàng trăm tỷ tham số, thu nạp dữ liệu từ nhiều nguồn như Internet, Common Crawl và Wikipedia\"\\n  ],\\n  \"questions\": [\\n    {\\n      \"question\": \"LLM là viết tắt của cụm từ nào?\",\\n      \"options\": {\\n        \"A\": \"Large Learning Machines\",\\n        \"B\": \"Linguistic Language Models\", \\n        \"C\": \"Large Language Models\",\\n        \"D\": \"Layered Learning Models\"\\n      },\\n      \"correct_answer\": \"C\"\\n    },\\n    {\\n      \"question\": \"Bộ chuyển hóa cơ bản của LLM bao gồm những thành phần nào?\",\\n      \"options\": {\\n        \"A\": \"Bộ xử lý và bộ nhớ\",\\n        \"B\": \"Bộ mã hóa và bộ giải mã\", \\n        \"C\": \"Bộ đầu vào và bộ đầu ra\",\\n        \"D\": \"Bộ học và bộ dự đoán\"\\n      },\\n      \"correct_answer\": \"B\"\\n    },\\n    {\\n      \"question\": \"Điểm khác biệt chính giữa bộ chuyển hóa và RNN là gì?\",\\n      \"options\": {\\n        \"A\": \"RNN xử lý song song còn bộ chuyển hóa xử lý tuần tự\",\\n        \"B\": \"Bộ chuyển hóa xử lý song song toàn bộ trình tự còn RNN xử lý tuần tự\",\\n        \"C\": \"RNN có nhiều tham số hơn bộ chuyển hóa\",\\n        \"D\": \"Bộ chuyển hóa chỉ xử lý văn bản ngắn\"\\n      },\\n      \"correct_answer\": \"B\"\\n    },\\n    {\\n      \"question\": \"LLM có thể thu nạp dữ liệu từ những nguồn nào được đề cập?\",\\n      \"options\": {\\n        \"A\": \"Chỉ từ Wikipedia\",\\n        \"B\": \"Chỉ từ Common Crawl\", \\n        \"C\": \"Từ Internet, Common Crawl và Wikipedia\",\\n        \"D\": \"Chỉ từ sách và tài liệu học thuật\"\\n      },\\n      \"correct_answer\": \"C\"\\n    },\\n    {\\n      \"question\": \"Quá trình đào tạo của bộ chuyển hóa được mô tả chính xác nhất là gì?\",\\n      \"options\": {\\n        \"A\": \"Đào tạo có giám sát hoàn toàn\",\\n        \"B\": \"Đào tạo không giám sát hoặc tự học\",\\n        \"C\": \"Đào tạo bán giám sát\",\\n        \"D\": \"Không cần đào tạo\"\\n      },\\n      \"correct_answer\": \"B\"\\n    }\\n  ],\\n  \"grading\": {\\n    \"score\": null,\\n    \"feedback\": \"\",\\n    \"improvement\": \"\"\\n  }\\n}'}, 'finish_reason': 'stop', 'content_filter_results': {'hate': {'filtered': False}, 'self_harm': {'filtered': False}, 'sexual': {'filtered': False}, 'violence': {'filtered': False}, 'jailbreak': {'filtered': False, 'detected': False}, 'profanity': {'filtered': False, 'detected': False}}}], 'usage': {'prompt_tokens': 974, 'completion_tokens': 857, 'total_tokens': 1831, 'prompt_tokens_details': None, 'completion_tokens_details': None}, 'system_fingerprint': ''}\n",
      "\n",
      "=== PARSED OUTPUT ===\n",
      "{\n",
      "  \"summary\": [\n",
      "    \"LLM là các mô hình học sâu lớn được đào tạo trước trên lượng dữ liệu khổng lồ\",\n",
      "    \"Kiến trúc bộ chuyển hóa gồm mã hóa và giải mã với cơ chế tự tập trung, giúp hiểu mối quan hệ giữa từ và cụm từ\",\n",
      "    \"Bộ chuyển hóa thực hiện đào tạo không giám sát, tự học ngữ pháp, ngôn ngữ và kiến thức cơ bản\",\n",
      "    \"Khác với RNN xử lý tuần tự, bộ chuyển hóa xử lý song song toàn bộ trình tự, giảm đáng kể thời gian đào tạo\",\n",
      "    \"Kiến trúc cho phép mô hình cực lớn với hàng trăm tỷ tham số, thu nạp dữ liệu từ nhiều nguồn như Internet, Common Crawl và Wikipedia\"\n",
      "  ],\n",
      "  \"questions\": [\n",
      "    {\n",
      "      \"question\": \"LLM là viết tắt của cụm từ nào?\",\n",
      "      \"options\": {\n",
      "        \"A\": \"Large Learning Machines\",\n",
      "        \"B\": \"Linguistic Language Models\", \n",
      "        \"C\": \"Large Language Models\",\n",
      "        \"D\": \"Layered Learning Models\"\n",
      "      },\n",
      "      \"correct_answer\": \"C\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Bộ chuyển hóa cơ bản của LLM bao gồm những thành phần nào?\",\n",
      "      \"options\": {\n",
      "        \"A\": \"Bộ xử lý và bộ nhớ\",\n",
      "        \"B\": \"Bộ mã hóa và bộ giải mã\", \n",
      "        \"C\": \"Bộ đầu vào và bộ đầu ra\",\n",
      "        \"D\": \"Bộ học và bộ dự đoán\"\n",
      "      },\n",
      "      \"correct_answer\": \"B\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Điểm khác biệt chính giữa bộ chuyển hóa và RNN là gì?\",\n",
      "      \"options\": {\n",
      "        \"A\": \"RNN xử lý song song còn bộ chuyển hóa xử lý tuần tự\",\n",
      "        \"B\": \"Bộ chuyển hóa xử lý song song toàn bộ trình tự còn RNN xử lý tuần tự\",\n",
      "        \"C\": \"RNN có nhiều tham số hơn bộ chuyển hóa\",\n",
      "        \"D\": \"Bộ chuyển hóa chỉ xử lý văn bản ngắn\"\n",
      "      },\n",
      "      \"correct_answer\": \"B\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"LLM có thể thu nạp dữ liệu từ những nguồn nào được đề cập?\",\n",
      "      \"options\": {\n",
      "        \"A\": \"Chỉ từ Wikipedia\",\n",
      "        \"B\": \"Chỉ từ Common Crawl\", \n",
      "        \"C\": \"Từ Internet, Common Crawl và Wikipedia\",\n",
      "        \"D\": \"Chỉ từ sách và tài liệu học thuật\"\n",
      "      },\n",
      "      \"correct_answer\": \"C\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Quá trình đào tạo của bộ chuyển hóa được mô tả chính xác nhất là gì?\",\n",
      "      \"options\": {\n",
      "        \"A\": \"Đào tạo có giám sát hoàn toàn\",\n",
      "        \"B\": \"Đào tạo không giám sát hoặc tự học\",\n",
      "        \"C\": \"Đào tạo bán giám sát\",\n",
      "        \"D\": \"Không cần đào tạo\"\n",
      "      },\n",
      "      \"correct_answer\": \"B\"\n",
      "    }\n",
      "  ],\n",
      "  \"grading\": {\n",
      "    \"score\": null,\n",
      "    \"feedback\": \"\",\n",
      "    \"improvement\": \"\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_URL = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "HF_Token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HF_Token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def query(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-ai/DeepSeek-V3.2-Exp:novita\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.2,   \n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# =========== DỮ LIỆU NGỮ CẢNH ===============\n",
    "text = \"\"\"\n",
    "Mô hình ngôn ngữ lớn, còn gọi là LLM, là các mô hình học sâu rất lớn, được đào tạo trước dựa trên một lượng dữ liệu khổng lồ. Bộ chuyển hóa cơ bản là tập hợp các mạng nơ-ron có một bộ mã hóa và một bộ giải mã với khả năng tự tập trung. Bộ mã hóa và bộ giải mã trích xuất ý nghĩa từ một chuỗi văn bản và hiểu mối quan hệ giữa các từ và cụm từ trong đó.\n",
    "\n",
    "Bộ chuyển hóa LLM có khả năng đào tạo không có giám sát, mặc dù lời giải thích chính xác hơn là bộ chuyển hóa thực hiện việc tự học. Thông qua quá trình này, bộ chuyển hóa học cách hiểu ngữ pháp, ngôn ngữ và kiến thức cơ bản.\n",
    "\n",
    "Khác với các mạng nơ-ron hồi quy (RNN) trước đó thường xử lý tuần tự dữ liệu đầu vào, bộ chuyển hóa xử lý song song toàn bộ trình tự. Điều này cho phép các nhà khoa học dữ liệu sử dụng GPU để đào tạo các LLM dựa trên bộ chuyển hóa, qua đó giảm đáng kể thời gian đào tạo.\n",
    "\n",
    "Kiến trúc mạng nơ-ron của bộ chuyển hóa cho phép việc sử dụng các mô hình rất lớn, thường có hàng trăm tỷ tham số. Các mô hình quy mô lớn như vậy có thể thu nạp một lượng dữ liệu khổng lồ, thường là từ Internet, nhưng cũng từ các nguồn, ví dụ như Common Crawl với hơn 50 tỷ trang web, và Wikipedia với khoảng 57 triệu trang.\n",
    "\"\"\"\n",
    "\n",
    "user_answer = \"\"  \n",
    "\n",
    "\n",
    "# =========== NHÚNG PROMPT TỐI ƯU ===============\n",
    "prompt = f\"\"\"\n",
    "Bạn là DeepSeek, một mô hình phân tích logic và ngôn ngữ tiếng Việt cực mạnh.\n",
    "Hãy thực hiện CHÍNH XÁC 3 nhiệm vụ sau trên cùng một văn bản:\n",
    "\n",
    "======================\n",
    "NHIỆM VỤ 1: TÓM TẮT\n",
    "======================\n",
    "- Rút ra 3–6 ý chính quan trọng nhất.\n",
    "- Viết ngắn gọn, đúng trọng tâm.\n",
    "- Không thêm thông tin không tồn tại.\n",
    "\n",
    "==============================\n",
    "NHIỆM VỤ 2: TẠO CÂU HỎI + ĐÁP ÁN\n",
    "==============================\n",
    "- Tạo 5 câu hỏi trắc nghiệm A/B/C/D.\n",
    "- Mỗi câu phải kiểm tra hiểu nội dung.\n",
    "- Mỗi câu phải có đúng 1 đáp án đúng.\n",
    "- Không tạo câu hỏi mơ hồ hoặc không có trong văn bản.\n",
    "\n",
    "=============================\n",
    "NHIỆM VỤ 3: CHẤM ĐIỂM USER\n",
    "=============================\n",
    "Nếu người dùng có trả lời:\n",
    "- So sánh logic giữa đáp án đúng và câu trả lời người dùng.\n",
    "- Chấm điểm theo thang 0–100.\n",
    "- Viết nhận xét rõ ràng.\n",
    "- Gợi ý cải thiện.\n",
    "\n",
    "Nếu người dùng KHÔNG trả lời:\n",
    "- Hãy để trống trường grading.\n",
    "\n",
    "======================\n",
    "RÀNG BUỘC\n",
    "======================\n",
    "- Không bịa đặt.\n",
    "- Chỉ dựa trên văn bản.\n",
    "- Trả về đúng JSON.\n",
    "\n",
    "======================\n",
    "VĂN BẢN\n",
    "======================\n",
    "{text}\n",
    "\n",
    "======================\n",
    "TRẢ LỜI USER\n",
    "======================\n",
    "{user_answer}\n",
    "\n",
    "======================\n",
    "JSON OUTPUT\n",
    "======================\n",
    "{{\n",
    "  \"summary\": [],\n",
    "  \"questions\": [],\n",
    "  \"grading\": {{\n",
    "    \"score\": null,\n",
    "    \"feedback\": \"\",\n",
    "    \"improvement\": \"\"\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# =========== GỌI MODEL ===============\n",
    "result = query(prompt)\n",
    "\n",
    "# =========== IN KẾT QUẢ ===============\n",
    "print(\"\\n=== RAW RESPONSE ===\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\n=== PARSED OUTPUT ===\")\n",
    "print(result[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f2c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"summary\": [\n",
      "        \"LLM là mô hình học sâu lớn được đào tạo trước trên lượng dữ liệu khổng lồ\",\n",
      "        \"Bộ chuyển hóa Transformer gồm mã hóa và giải mã, sử dụng cơ chế tự tập trung để hiểu mối quan hệ giữa các từ\",\n",
      "        \"Transformer thực hiện đào tạo không giám sát, tự học ngữ pháp, ngôn ngữ và kiến thức cơ bản\",\n",
      "        \"Khác với RNN xử lý tuần tự, Transformer xử lý song song toàn bộ trình tự, giảm thời gian đào tạo nhờ GPU\",\n",
      "        \"Transformer cho phép xây dựng mô hình cực lớn với hàng trăm tỷ tham số, thu nạp dữ liệu từ nhiều nguồn như Internet, Common Crawl và Wikipedia\"\n",
      "    ],\n",
      "    \"questions\": [\n",
      "        {\n",
      "            \"question\": \"LLM là viết tắt của cụm từ nào?\",\n",
      "            \"options\": {\n",
      "                \"A\": \"Large Learning Machines\",\n",
      "                \"B\": \"Linguistic Language Models\", \n",
      "                \"C\": \"Large Language Models\",\n",
      "                \"D\": \"Logical Learning Models\"\n",
      "            },\n",
      "            \"correct_answer\": \"C\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"Bộ chuyển hóa Transformer bao gồm những thành phần chính nào?\",\n",
      "            \"options\": {\n",
      "                \"A\": \"Bộ nhập và bộ xuất\",\n",
      "                \"B\": \"Bộ mã hóa và bộ giải mã\",\n",
      "                \"C\": \"Bộ xử lý và bộ lưu trữ\",\n",
      "                \"D\": \"Bộ đọc và bộ ghi\"\n",
      "            },\n",
      "            \"correct_answer\": \"B\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"Điểm khác biệt chính giữa Transformer và RNN là gì?\",\n",
      "            \"options\": {\n",
      "                \"A\": \"Transformer xử lý tuần tự, RNN xử lý song song\",\n",
      "                \"B\": \"Transformer xử lý song song, RNN xử lý tuần tự\",\n",
      "                \"C\": \"Transformer nhỏ hơn RNN\",\n",
      "                \"D\": \"Transformer chỉ dùng CPU, RNN dùng GPU\"\n",
      "            },\n",
      "            \"correct_answer\": \"B\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"Transformer học được những gì thông qua quá trình tự học?\",\n",
      "            \"options\": {\n",
      "                \"A\": \"Chỉ học ngữ pháp\",\n",
      "                \"B\": \"Chỉ học từ vựng\", \n",
      "                \"C\": \"Ngữ pháp, ngôn ngữ và kiến thức cơ bản\",\n",
      "                \"D\": \"Chỉ học cú pháp câu\"\n",
      "            },\n",
      "            \"correct_answer\": \"C\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"Các nguồn dữ liệu nào được đề cập để đào tạo LLM?\",\n",
      "            \"options\": {\n",
      "                \"A\": \"Chỉ từ Internet\",\n",
      "                \"B\": \"Chỉ từ sách giáo khoa\",\n",
      "                \"C\": \"Internet, Common Crawl và Wikipedia\", \n",
      "                \"D\": \"Chỉ từ Common Crawl\"\n",
      "            },\n",
      "            \"correct_answer\": \"C\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def summarize_and_generate(raw_text, number_of_questions=5):\n",
    "    \"\"\"\n",
    "    Hàm tổng hợp: tóm tắt + sinh câu hỏi\n",
    "    Trả về dict {\n",
    "        \"summary\": str,\n",
    "        \"questions\": list of {question_text, ideal_answer}\n",
    "    }\n",
    "    \"\"\"\n",
    "    API_URL = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "    HF_Token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {HF_Token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    def query(prompt):\n",
    "        payload = {\n",
    "            \"model\": \"deepseek-ai/DeepSeek-V3.2-Exp:novita\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.2,   \n",
    "        }\n",
    "\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    # =========== DỮ LIỆU NGỮ CẢNH ===============\n",
    "    text = raw_text\n",
    "\n",
    "    # =========== NHÚNG PROMPT TỐI ƯU ===============\n",
    "    prompt = f\"\"\"\n",
    "    Bạn là DeepSeek, một mô hình phân tích logic và ngôn ngữ tiếng Việt cực mạnh.\n",
    "    Hãy thực hiện CHÍNH XÁC 2 nhiệm vụ sau trên cùng một văn bản:\n",
    "\n",
    "    ======================\n",
    "    NHIỆM VỤ 1: TÓM TẮT\n",
    "    ======================\n",
    "    - Rút ra các ý chính quan trọng nhất.\n",
    "    - Viết ngắn gọn, đúng trọng tâm.\n",
    "    - Không thêm thông tin không tồn tại.\n",
    "\n",
    "    ==============================\n",
    "    NHIỆM VỤ 2: TẠO CÂU HỎI + ĐÁP ÁN\n",
    "    ==============================\n",
    "    - Tạo {number_of_questions} câu hỏi trắc nghiệm A/B/C/D.\n",
    "    - Mỗi câu phải kiểm tra hiểu nội dung.\n",
    "    - Mỗi câu phải có đúng 1 đáp án đúng.\n",
    "    - Không tạo câu hỏi mơ hồ hoặc không có trong văn bản.\n",
    "\n",
    "    ======================\n",
    "    RÀNG BUỘC\n",
    "    ======================\n",
    "    - Không bịa đặt.\n",
    "    - Chỉ dựa trên văn bản.\n",
    "    - Trả về đúng JSON.\n",
    "\n",
    "    ======================\n",
    "    VĂN BẢN\n",
    "    ======================\n",
    "    {text}\n",
    "\n",
    "    ======================\n",
    "    JSON OUTPUT\n",
    "    ======================\n",
    "    {{\n",
    "    \"summary\": [],\n",
    "    \"questions\": [],\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # =========== GỌI MODEL ===============\n",
    "    result = query(prompt)\n",
    "\n",
    "    # =========== IN KẾT QUẢ ===============\n",
    "    return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "text =  \"\"\"\n",
    "    Mô hình ngôn ngữ lớn, còn gọi là LLM, là các mô hình học sâu rất lớn, được đào tạo trước dựa trên một lượng dữ liệu khổng lồ. Bộ chuyển hóa cơ bản là tập hợp các mạng nơ-ron có một bộ mã hóa và một bộ giải mã với khả năng tự tập trung. Bộ mã hóa và bộ giải mã trích xuất ý nghĩa từ một chuỗi văn bản và hiểu mối quan hệ giữa các từ và cụm từ trong đó.\n",
    "\n",
    "    Bộ chuyển hóa LLM có khả năng đào tạo không có giám sát, mặc dù lời giải thích chính xác hơn là bộ chuyển hóa thực hiện việc tự học. Thông qua quá trình này, bộ chuyển hóa học cách hiểu ngữ pháp, ngôn ngữ và kiến thức cơ bản.\n",
    "\n",
    "    Khác với các mạng nơ-ron hồi quy (RNN) trước đó thường xử lý tuần tự dữ liệu đầu vào, bộ chuyển hóa xử lý song song toàn bộ trình tự. Điều này cho phép các nhà khoa học dữ liệu sử dụng GPU để đào tạo các LLM dựa trên bộ chuyển hóa, qua đó giảm đáng kể thời gian đào tạo.\n",
    "\n",
    "    Kiến trúc mạng nơ-ron của bộ chuyển hóa cho phép việc sử dụng các mô hình rất lớn, thường có hàng trăm tỷ tham số. Các mô hình quy mô lớn như vậy có thể thu nạp một lượng dữ liệu khổng lồ, thường là từ Internet, nhưng cũng từ các nguồn, ví dụ như Common Crawl với hơn 50 tỷ trang web, và Wikipedia với khoảng 57 triệu trang.\n",
    "    \"\"\"\n",
    "\n",
    "print(summarize_and_generate(text, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5cab09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
