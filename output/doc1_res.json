{
    "input_path": "doc1.png",
    "page_index": null,
    "model_settings": {
        "use_doc_preprocessor": true,
        "use_textline_orientation": false
    },
    "doc_preprocessor_res": {
        "input_path": null,
        "page_index": null,
        "model_settings": {
            "use_doc_orientation_classify": false,
            "use_doc_unwarping": false
        },
        "angle": -1
    },
    "dt_polys": [
        [
            [
                17,
                21
            ],
            [
                158,
                21
            ],
            [
                158,
                46
            ],
            [
                17,
                46
            ]
        ],
        [
            [
                18,
                87
            ],
            [
                1021,
                87
            ],
            [
                1021,
                109
            ],
            [
                18,
                109
            ]
        ],
        [
            [
                18,
                124
            ],
            [
                618,
                124
            ],
            [
                618,
                145
            ],
            [
                18,
                145
            ]
        ],
        [
            [
                18,
                188
            ],
            [
                638,
                188
            ],
            [
                638,
                209
            ],
            [
                18,
                209
            ]
        ]
    ],
    "text_det_params": {
        "limit_side_len": 64,
        "limit_type": "min",
        "thresh": 0.3,
        "max_side_limit": 4000,
        "box_thresh": 0.6,
        "unclip_ratio": 1.5
    },
    "text_type": "general",
    "textline_orientation_angles": [
        -1,
        -1,
        -1,
        -1
    ],
    "text_rec_score_thresh": 0.0,
    "return_word_box": false,
    "rec_texts": [
        "Quantization",
        "Quantization reduces the memory burden of large models by representing the weights in a lower precision. Refer to",
        "the Quantization overview for more available quantization backends.",
        "The example below uses bitsandbytes to quantize the weights to 8-bits."
    ],
    "rec_scores": [
        0.9999906420707703,
        0.9892130494117737,
        0.9959542751312256,
        0.9916439652442932
    ],
    "rec_polys": [
        [
            [
                17,
                21
            ],
            [
                158,
                21
            ],
            [
                158,
                46
            ],
            [
                17,
                46
            ]
        ],
        [
            [
                18,
                87
            ],
            [
                1021,
                87
            ],
            [
                1021,
                109
            ],
            [
                18,
                109
            ]
        ],
        [
            [
                18,
                124
            ],
            [
                618,
                124
            ],
            [
                618,
                145
            ],
            [
                18,
                145
            ]
        ],
        [
            [
                18,
                188
            ],
            [
                638,
                188
            ],
            [
                638,
                209
            ],
            [
                18,
                209
            ]
        ]
    ],
    "rec_boxes": [
        [
            17,
            21,
            158,
            46
        ],
        [
            18,
            87,
            1021,
            109
        ],
        [
            18,
            124,
            618,
            145
        ],
        [
            18,
            188,
            638,
            209
        ]
    ]
}